{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Features\n",
    "\n",
    "Prof. Dr. Georgios K. Ouzounis<br/>\n",
    "[georgios.ouzounis@go.kauko.lt](georgios.ouzounis@go.kauko.lt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contents\n",
    "\n",
    "- features - definition \n",
    "- feature impact\n",
    "- feature selection\n",
    "- feature engineering\n",
    "- feature vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features - Definition\n",
    "\n",
    "A feature is an individual measurable property or characteristic of a phenomenon being observed [Wikipedia](https://en.wikipedia.org/wiki/Feature_(machine_learning)).\n",
    "\n",
    "Choosing informative, discriminating and independent features is a crucial step for effective algorithms in pattern recognition, classification and regression. \n",
    "\n",
    "Features are usually numeric, but structural features such as strings and graphs exist too.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In datasets, features (or variables / attributes) appear as columns:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://3gp10c1vpy442j63me73gy3s-wpengine.netdna-ssl.com/wp-content/uploads/2018/03/Screen-Shot-2018-03-22-at-8.29.31-AM.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The image above contains a snippet of data from a public dataset with information about passengers on Titanic’s maiden voyage. Each feature, or column, represents a measurable piece of data that can be used for analysis: Name, Age, Sex, Fare, and so on.  [Source](https://www.datarobot.com/wiki/feature/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Features are the basic building blocks of datasets. The quality of the features in your dataset has a major impact on the quality of the insights you will be able to get when you use that dataset for machine learning. <br/>\n",
    "\n",
    "You can improve the quality of your dataset’s features with processes like:\n",
    "\n",
    "1. feature impact assessment,\n",
    "2. feature selection,\n",
    "3. feature engineering. \n",
    "\n",
    "All three are difficult and tedious. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Impact"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature impact identifies which features in a dataset have the greatest effect on the outcomes of a machine learning model.\n",
    "\n",
    "Depending on their properties, different machine learning algorithms focus on different features in a dataset. \n",
    "\n",
    "**Impact Example:** features that have strong linear trends (that is, they increase or decrease at a steady rate) will have high impacts in linear-based methods like regression, while nonlinear-based methods will leverage the more complex relationships in the data. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the big data world the size and dimensionality of data-sets are unprecedented.\n",
    "\n",
    "Identifying relevant and valuable information allows us to focus on the factors that matter the most when building data models, saving both time and resources.\n",
    "\n",
    "Feature impact can be computed by a handful of machine learning algorithms and usually requires intuition and a deeper insight into your data. \n",
    "\n",
    "You may practise it with empirical procedures.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature impact is used in both:\n",
    "\n",
    "1. feature selection for improving the accuracy of your models, \n",
    "2. identifying target leakage for avoiding highly inaccurate models. If a single feature is extremely impactful on a model’s outcomes, that is a primary indicator of target leakage. \n",
    "\n",
    "Target or data leakage is the situation in which you train your algorithm on a dataset that includes information that would not be available at the time of prediction, when you apply that model to data you collect in the future. \n",
    "Since it already knows the actual outcomes, the model’s results will be unrealistically accurate for the training data, like bringing an answer sheet into an exam.."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The initial set of raw features can be redundant and too large to be managed!\n",
    "\n",
    "Select a subset of features, or construct a new and reduced set of features to facilitate learning, and to improve generalization and interpretability\n",
    "\n",
    "**Selection example:** if you’re trying to predict flight delays, today’s temperature may be important, but the temperature three months ago will be not.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Good feature selection eliminates irrelevant or redundant columns from your dataset without sacrificing accuracy. \n",
    "\n",
    "Feature selection, by contrast to dimensionality reduction,  doesn’t involve creating new features or transforming existing ones, but rather getting rid of the ones that don’t add value to your analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The benefits of feature selection for machine learning include:\n",
    "- Reducing the chance of overfitting.\n",
    "- Reducing the CPU, I/O, and RAM load the production system needs to build and use the model by lowering the number of operations it takes to read and preprocess data and perform data science, improving algorithm run speed.\n",
    "- Increasing the model’s interpretability by revealing the most informative factors that drive the model’s outcomes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Useful Links\n",
    "\n",
    "| blog | article |\n",
    "|-----|:--------|\n",
    "|<img src=\"https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-content/uploads/2018/09/icon-100x100.png\" style=\"float: left; margin-right: 10px;\" width=\"100\"/>|[An Introduction to Feature Selection](https://machinelearningmastery.com/category/machine-learning-process/) by Jason Brownlee on October 6, 2014 in Machine Learning Process |\n",
    "| <img src=\"http://www.euro-langues.org/wp-content/uploads/2019/05/1*F0LADxTtsKOgmPa-_7iUEQ.jpeg\" style=\"float: left; margin-right: 10px;\" width=\"100\"/>|[Why, How and When to Apply Feature Selection](https://towardsdatascience.com/why-how-and-when-to-apply-feature-selection-e9c69adfabf2) by Sudharsan Asaithambi, Jan 31, 2018 in Towards Data Science\n",
    "|\n",
    "| <img src=\"https://cdn-images-1.medium.com/max/1600/1*emiGsBgJu2KHWyjluhKXQw.png\" style=\"float: left; margin-right: 10px;\" width=\"100\"/>| [3 Effective Feature Selection Strategies](https://medium.com/ai%C2%B3-theory-practice-business/three-effective-feature-selection-strategies-e1f86f331fb1) by  Christopher Dossman, Oct. 22, 2017 in AI3 | Theory Practice Business\n",
    "|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "“Feature engineering is the art part of data science.” \n",
    "\n",
    "Sergey Yurgenson, former #1 ranked global competitive data scientist on Kaggle\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature engineering is the addition and construction of additional variables, or features, to your dataset to improve machine learning model performance and accuracy. \n",
    "\n",
    "Higher-level features can be obtained from already available features and added to the feature vector; for example, for the study of diseases the feature 'Age' is useful and is defined as Age = 'Year of death' minus 'Year of birth' . \n",
    "\n",
    "The most effective feature engineering is based on sound knowledge of the business problem for which you’re trying to gain deeper insight and your available data sources. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It’s an exercise in engagement with the meaning of the problem and the data. For example, you might improve a model used to estimate likely loan defaults by finding external sources of relevant data, such as local unemployment rates or housing price trends.\n",
    "\n",
    "Feature Engineering requires the experimentation of multiple possibilities and the combination of automated techniques with the intuition and knowledge of the domain expert. \n",
    "\n",
    "Automating this process is feature learning, where a machine not only uses features for learning, but learns the features itself."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating new features gives you a deeper understanding of your data and results in more valuable insights. When done correctly, feature engineering is one of the most valuable techniques of data science, but it’s also one of the most challenging:\n",
    "\n",
    "“Coming up with features is difficult, time-consuming, [and] requires expert knowledge. \n",
    "— Andrew Ng,  chief scientist of Baidu, co-chairman and co-founder of Coursera, and adjunct professor at Stanford University\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Useful Links\n",
    "\n",
    "| blog | article |\n",
    "|-----|:--------|\n",
    "|<img src=\"https://3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com/wp-content/uploads/2018/09/icon-100x100.png\" style=\"float: left; margin-right: 10px;\" width=\"100\"/>| [Discover Feature Engineering, How to Engineer Features and How to Get Good at It](https://machinelearningmastery.com/discover-feature-engineering-how-to-engineer-features-and-how-to-get-good-at-it/) by Jason Brownlee on September 26, 2014 in Machine Learning Process |\n",
    "|<img src=\"http://www.euro-langues.org/wp-content/uploads/2019/05/1*F0LADxTtsKOgmPa-_7iUEQ.jpeg\" style=\"float: left; margin-right: 10px;\" width=\"100\"/>| [Understanding Feature Engineering (Part 1) — Continuous Numeric Data: Strategies for working with continuous, numerical data](https://towardsdatascience.com/understanding-feature-engineering-part-1-continuous-numeric-data-da4e47099a7b), by Dipanjan (DJ) Sarkar, Data Scientist @Intel, Jan 4, 2018 in Towards Data Science |\n",
    "|<img src=\"https://www.datacamp.com/datacamp-sq.png\" style=\"float: left; margin-right: 10px;\" width=\"100\"/>| [Machine Learning with Kaggle: Feature Engineering](https://www.datacamp.com/community/tutorials/feature-engineering-kaggle) by Hugo Bowne-Anderson, Jan. 10, 2018 in Data Camp |\n",
    "|<img src=\"https://jakevdp.github.io/PythonDataScienceHandbook/figures/PDSH-cover-small.png\" style=\"float: left; margin-right: 10px;\" width=\"100\"/>| [Feature Engineering](https://jakevdp.github.io/PythonDataScienceHandbook/05.04-feature-engineering.html) by Jake VanderPlas, Nov. 2016 in Python Data Science Handbook |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Vectors\n",
    "\n",
    "A feature vector is an n-dimensional vector of numerical features that represent some object. \n",
    "\n",
    "Feature vectors offer a richer numerical representation of objects which may facilitate processing and statistical analysis. \n",
    "\n",
    "Feature vectors are equivalent to the vectors of explanatory variables used in statistical procedures such as linear regression. \n",
    "\n",
    "Feature vectors are often combined with weights using a dot product in order to construct a linear predictor function that is used to determine a score for making a prediction\n",
    "\n",
    "The vector space associated with feature vectors is often called the feature space. \n",
    "\n",
    "Dimensionality Reduction: In order to reduce the dimensionality of the feature space, a number of dimensionality reduction techniques can be employed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
